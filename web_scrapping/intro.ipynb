{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "b1ee877665787ef736d896fd412d6716aab4e647147ff7517dc995e63a594f98"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Web scrapping"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# The Tools\n",
    "For this particular task, I am going to use 2 very common python tools for scraping the site:\n",
    "\n",
    "- BeautifulSoup to parse the data\n",
    "- Requests to get the data from the website.\n",
    "\n",
    "Strictly speaking, Requests is not being used for much in this case but I think it makes sense to start using it. If/when you start getting more complicated situations, you’ll be happy you are already using it.\n",
    "\n",
    "Scrapy is another powerful tool for doing web scraping but for my needs BeautifulSoup was perfect so that’s what I’m sticking with for this article. Maybe I’ll look at it for a future article.\n",
    "\n",
    "Once I scrape the data, I’ll convert it to a pandas DataFrame so that I can analyze and plot the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}